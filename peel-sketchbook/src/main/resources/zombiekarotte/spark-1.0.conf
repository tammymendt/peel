system {
    spark {
        path {
            # uncomment the following section if you want to extract an archive on every run
            archive = {
                src = ${app.path.systems}"/spark-1.0.0-bin-hadoop1.tgz"
                dst = ${app.path.systems}
            }
            home = ${app.path.systems}"/spark-1.0.0-bin-hadoop1"
        }
        config {
            # put list of slaves
            slaves = ${system.default.config.slaves}
            # spark-env.sh entries
            env {
                HADOOP_CONF_DIR = ${system.hadoop-1.path.config}
                SPARK_EXECUTOR_MEMORY = "1024m"
                SPARK_WORKER_MEMORY = "1024m"
            }
            defaults {
                spark.master = "spark://localhost:7077"
                spark.executor.memory = "1024m"
                spark.eventLog.enabled = "true"
                spark.eventLog.dir = "file://"${system.spark.path.log}
            }

        }
    }
}
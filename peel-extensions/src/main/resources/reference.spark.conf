system {
    spark {
        user = ${system.default.user}
        group = ${system.default.group}
        path {
            # uncomment the following section if you want to extract an archive on every run
            # archive = {
            #     src = ${app.path.downloads}"/spark-VERSION.tgz"
            #      dst = ${app.path.systems}
            # }
            home = ${app.path.systems}"/spark"
            config = ${system.spark.path.home}"/conf"
            log = ${system.spark.path.home}"/logs"
        }
        startup {
            max.attempts = ${system.default.startup.max.attempts}
            polling {
                counter = ${system.default.startup.polling.counter}
                interval = ${system.default.startup.polling.interval}
            }
        }
        config {
            # put list of slaves
            slaves = ${system.default.config.slaves}
            # spark-env.sh entries
            env {
                JAVA_HOME = ${system.default.config.java.home}
                SPARK_MASTER_WEBUI_PORT = 8060
                SPARK_WORKER_WEBUI_PORT = 8061
                SPARK_WORKER_CORES = ${system.default.config.parallelism.per-node}
                SPARK_EXECUTOR_CORES = ${system.default.config.parallelism.per-node}
                SPARK_EXECUTOR_MEMORY = "512m"
            }
            defaults {
                spark.master = "spark://localhost:7070"
                spark.executor.memory = "512m"
                spark.eventLog.enabled = "true"
                spark.eventLog.dir = "file://"${system.spark.path.log}
            }

        }
    }
}